---
title: "6. Controls: part 1"
author: "Carmen Coronas"
output: html_document
date: "November 2024"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Controls: part 1

## Estimating consumer demand and elasticities

```{r oj coef}
oj <- read.csv("../Data/oj.csv")
basefit <- lm(log(sales) ~ log(price), data=oj)
coef(basefit)
```

```{r oj fit}
brandfit <- lm(log(sales) ~ brand + log(price), data=oj)
coef(brandfit)
```

```{r oj reg}
pricereg <- lm(log(sales) ~ brand, data=oj)
phat <- predict(pricereg, newdata=oj) 
presid <- log(oj$price) - phat
residfit <- lm(log(sales) ~ presid, data=oj)
coef(basefit)
```

## Linear Treatment Effects Model. Abortion example. 
```{r summary data: abortion}
data <- read.table("/Users/carmencilla/Desktop/RPractice_DSHRA/Data/abortion.dat", skip=1, sep="\t")
names(data) <- c("state","year","pop","y_viol","y_prop","y_murd",
	"a_murd","a_viol","a_prop",'prison','police',
	'ur','inc','pov','afdc','gun','beer')
data <- data[!(data$state%in%c(2,9,12)),] # AK, DC, HA are strange places
data <- data[data$year>84 & data$year<98,] # incomplete data outside these years
data$pop <- log(data$pop)
t <- data$year - 85
s <- factor(data$state) ## states are numbered alphabetically
controls <- data.frame(data[,c(3,10:17)])
## y is de-trended log crime rate, a is as described below
## note we also have violent and property crime versions
y <- data$y_murd
d <- data$a_murd
```

```{r first step}
summary(orig <- glm(y ~ d + t + s +., data=controls) )$coef['d',]

dcoef <- summary(orig <- glm(y ~ d + t + s +., data=controls) )$coef['d',][1]

exp(dcoef) - 1
```

```{r cell phone data}
cell <- read.csv("/Users/carmencilla/Desktop/RPractice_DSHRA/Data/us_cellphone.csv")
cellrate <- 5*cell[,2]/(1000*cell[,3]) # center on 1985 and scale by 1997-1985
```

```{r plot correlation}
par(mai=c(.9,.9,.1,.1))
plot(1985:1997, tapply(d, t, mean), bty="n", xlab="year", ylab="rate", pch=21, bg=2)
points(1985:1997, cellrate, bg=4, pch=21)
legend("topleft", fill=c(2,4), legend=c("abortions","cellphones"), bty="n")
```

```{r mg effect}
phone <- cellrate[ t + 1 ]
tech <- summary(glm(y ~ phone + t + s +., data=controls))$coef['phone',]
phonecoef <- tech[1]
exp(phonecoef) - 1
```

```{r interact phone-abortion}
t <- factor(t)
interact <- glm(y ~ d + t + phone*s + .^2, data=controls)
summary(interact)$coef["d",]
```

```{r using lasso for abortion}
library(gamlr)
## refactor state to have NA reference level
sna <- factor(s, levels=c(NA,levels(s)), exclude=NULL)
x <- sparse.model.matrix( ~ t + phone*sna + .^2, data=controls)[,-1]
dim(x)
## naive lasso regression
naive <- cv.gamlr(cbind(d,x),y); head(coef(naive))
coef(naive)["d",] 
```

```{r lte for abortion}
treat <- cv.gamlr(x,d, lmr=1e-3); head(summary(treat))
predtreat <- predict(treat, x, select="min"); head(predtreat)
dhat <- drop(predtreat); length(dhat)
```

```{r XXX}
par(mai=c(.9,.9,.1,.1))
plot(dhat,d,bty="n",pch=21,bg=8, cex=.8, yaxt="n")
axis(2, at=c(0,1,2,3)) 
#no much room for experimentation here. 
```

```{r IS r2}
## IS R^2?
cor(drop(dhat),d)^2
## Note: IS R2 indicates how much independent signal you have for estimating 
coef(summary( glm( y ~ d + dhat) ))
# re-run lasso, with this (2nd column) included unpenalized (free=2)
causal <- cv.gamlr(cbind(d,dhat,x),y,free=2,lmr=1e-3)
coef(causal, select="min")["d",] 
# AICc says abortion rate has no causal effect on crime.
```

## Interpretation code above:   

After approximately 20-25 prompts to get the most accurate insights about the code with ChatGPT, we conclude the following:    

  - Data Preparation: The dataset includes variables such as detrended log crime rate (y), abortion rate (d), population, and other controls (e.g., income, gun laws). Data is cleaned to exclude incomplete entries and anomalous states like Alaska and DC. Interaction terms for state and year are created using sparse.model.matrix.   
  
  - Regression Analysis: A linear model estimates the relationship between abortion rates and crime, controlling for year (t) and state (s). The coefficient for abortion rates is exponentiated to assess the percentage impact. Cellphone adoption rates (cellrate) are added as a control to capture technological trends, and a regression shows their effect on crime, visualized alongside abortion rates in a plot.   
  
  - Lasso Regression: Sparse matrices and Lasso regression (gamlr) are applied to identify key predictors and reduce model complexity. The naive Lasso regression coefficient for d provides an initial assessment of its influence on crime trends.   
  
  - Treatment Effect Estimation: Orthogonal regression models are used to predict residual abortion rates after accounting for controls. The residuals (dhat) are visualized and analyzed to ensure proper treatment assignment.   
  
  - In-sample R2 is calculated to evaluate the modelâ€™s signal strength for estimating treatment effects.   
  
  - Causal Inference: A penalized regression model incorporating unpenalized treatment columns evaluates the causal impact of abortion rates on crime. Based on AICc, the results suggest that abortion rates have no significant causal effect on crime.

Note: This summary is an edited version of the own summary by ChatGPT on its own prompts. 

## Sample Splitting Algorithm
```{r sample splitting}
library(gamlr)
data(hockey)
head(goal, n=2)
player[1:2, 2:7] #players on ice. +1 is home players. 0 is off ice. 
team[1, 2:6] #Sparse Matrix with indicators for each team*season interaction: +1 for home team, -1 for away team. 
config[5:6, 2:7] #Special teams info. For example, S5v4 is a 5 on 4 powerplay, +1 if it is for the home-team and -1 for the away team.
```

```{r sample splittig example}
x <- cbind(config,team,player)
y <- goal$homegoal
fold <- sample.int(2,nrow(x),replace=TRUE) 
head(fold)

nhlprereg <- gamlr(x[fold==1,], y[fold==1],
	free=1:(ncol(config)+ncol(team)), 
	family="binomial", standardize=FALSE)
selected <- which(coef(nhlprereg)[-1,] != 0)
xnotzero <- as.data.frame(as.matrix(x[,selected]))
nhlmle <- glm( y ~ ., data=xnotzero, 
			subset=which(fold==2), family=binomial ) ##NOTE: takes a lot of time to process!!!!
```

```{r standard error}
summary(nhlmle)
```

```{r confidence intervals}
x[1,x[1,]!=0] #check first observation for players on the ice
fit <- predict(nhlmle, xnotzero[1,,drop=FALSE], type="response", se.fit=TRUE)$fit; fit
se.fit <- predict(nhlmle, xnotzero[1,,drop=FALSE], type="response", se.fit=TRUE)$se.fit; se.fit
CI = fit + c(-2,2)*se.fit
CI #90% confidence interval for probability that Edmonton scored the goal is 
```

## Interpretation code above: 
Same methodology as in the previous case with abortion rates.   

  - Data Overview and Setup: The dataset contains information on NHL hockey games, including player configurations (player), team interactions (team), and special team scenarios (config). Variables are encoded as sparse matrices with indicators for home and away teams. The response variable y represents whether the home team scored a goal.   
  
  - Modeling Process: The dataset is split into two random folds for training and testing. A Lasso regression model (gamlr) is applied to the training data (fold==1), with unpenalized columns for special team and team-season interactions. Non-zero coefficients are extracted to identify key predictors, which are then used to fit a logistic regression model (glm) on the test data (fold==2). This step may require significant processing time.    
  
  - Prediction and Confidence Intervals: Predictions are made using the logistic regression model for a specific observation. Standard errors are computed, and a 90% confidence interval is derived for the probability of a goal, providing insights into the likelihood of Edmonton scoring in the given scenario.   
  
  - In conclusion, this code applies Lasso regularization to identify key features and uses logistic regression for prediction and uncertainty quantification in hockey game outcomes.


